{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from cathedral_rl import cathedral_v0\n",
    "from cathedral_rl.game.manual_policy import ManualPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commandes \n",
    "\n",
    "\n",
    "Liste des touches possibles et leur effet :\n",
    "\n",
    "- Espace (K_SPACE) : Parcourt la liste des pièces disponibles en passant de la plus grande à la plus petite.\n",
    "- E (K_e) : Fait tourner la pièce dans le sens horaire (rotation à -90° par incrément, en tenant compte du plateau inversé).\n",
    "- Q (K_q) : Fait tourner la pièce dans le sens anti-horaire (rotation à +90° par incrément).\n",
    "- Flèche droite (K_RIGHT) : Déplace la pièce vers la droite, en vérifiant que le déplacement est légal.\n",
    "- Flèche gauche (K_LEFT) : Déplace la pièce vers la gauche, en vérifiant que le déplacement est légal.\n",
    "- Flèche haut (K_UP) : Déplace la pièce vers le haut (attention : en pygame, la coordonnée y augmente vers le bas), en vérifiant que le déplacement est légal.\n",
    "- Flèche bas (K_DOWN) : Déplace la pièce vers le bas, en vérifiant que le déplacement est légal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chose starting player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_player = \"human\" # human or AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if starting_player == \"AI\":\n",
    "    controlled_agent = \"player_0\"\n",
    "else:\n",
    "    controlled_agent = \"player_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DQN policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_size = 8\n",
    "\n",
    "epsilon_opponent = 0.1 \n",
    "\n",
    "method='eps_greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, obs_shape, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(obs_shape[2], 32, kernel_size=3, stride=1, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),              \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),             \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),              \n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        dummy = torch.zeros(1, obs_shape[2], obs_shape[0], obs_shape[1])\n",
    "        conv_out_size = self.conv(dummy).shape[1]\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)  \n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action_dqn(model, obs, action_mask, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).to(device) \n",
    "        q_values = model(obs_tensor).squeeze(0)  \n",
    "        \n",
    "    model.train()\n",
    "    mask = torch.tensor(action_mask, dtype=torch.bool, device=device)\n",
    "    q_values[~mask] = -1e8\n",
    "    action = torch.argmax(q_values).item()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = cathedral_v0.env(\n",
    "    board_size=8,\n",
    "    render_mode=\"human\",\n",
    "    per_move_rewards=True,\n",
    "    final_reward_score_difference=True,\n",
    ").unwrapped\n",
    "\n",
    "env.reset()\n",
    "\n",
    "n_actions = env.action_space(controlled_agent).n\n",
    "obs_shape = env.observe(controlled_agent)[\"observation\"].shape \n",
    "\n",
    "checkpoint = torch.load(\"models/10000ep.pth\", weights_only=False, map_location=torch.device('cpu'))\n",
    "\n",
    "policy_net = DQN(obs_shape, n_actions).to(device)\n",
    "policy_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "list_reward_training = checkpoint['list_reward']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play against AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Turn: 1 | (player_1) Legal pieces : [14], Legal moves total: 120, Remaining pieces: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 17:25:58.682 python[42405:6182076] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-12 17:25:58.682 python[42405:6182076] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn: 1 | Action: 1678, Piece: 14, Position: (3, 3), \n",
      "Turn: 1 | Reward: 0, Cumulative reward: 0, \n",
      "\n",
      "SCORE (player_1): 0.00, Squares/turn: 0.00, Remaining pieces difference: 0, Territory difference: 0\n",
      "SCORE (player_0): 0.00, Squares/turn: 0.00, Remaining pieces difference: 0, Territory difference: 0\n",
      "\n",
      "Turn: 2 | (player_0) Legal pieces : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], Legal moves total: 1139, Remaining pieces: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "Turn: 2 | Action: 1489, Piece: 13, Position: (1, 1), \n",
      "Turn: 2 | Reward: 3, Cumulative reward: 3, \n",
      "\n",
      "Turn: 3 | (player_1) Legal pieces : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], Legal moves total: 924, Remaining pieces: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "Turn: 3 | Action: 1612, Piece: 13, Position: (6, 1), \n",
      "Turn: 3 | Reward: 3, Cumulative reward: 3, \n",
      "\n",
      "SCORE (player_1): 5.00, Squares/turn: 5.00, Remaining pieces difference: 0, Territory difference: 0\n",
      "SCORE (player_0): 5.00, Squares/turn: 5.00, Remaining pieces difference: 0, Territory difference: 0\n",
      "\n",
      "Turn: 4 | (player_0) Legal pieces : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], Legal moves total: 641, Remaining pieces: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Turn: 4 | Action: 1400, Piece: 12, Position: (3, 6), \n",
      "Turn: 4 | Reward: 1, Cumulative reward: 7, \n",
      "\n",
      "Turn: 5 | (player_1) Legal pieces : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], Legal moves total: 467, Remaining pieces: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Turn: 5 | Action: 1347, Piece: 12, Position: (1, 5), \n",
      "Turn: 5 | Reward: 1, Cumulative reward: 7, \n",
      "\n",
      "SCORE (player_1): 5.00, Squares/turn: 5.00, Remaining pieces difference: 0, Territory difference: 0\n",
      "SCORE (player_0): 5.00, Squares/turn: 5.00, Remaining pieces difference: 0, Territory difference: 0\n",
      "\n",
      "Turn: 6 | (player_0) Legal pieces : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], Legal moves total: 336, Remaining pieces: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Turn: 6 | Action: 1282, Piece: 10, Position: (6, 6), \n",
      "Turn: 6 | Reward: 3, Cumulative reward: 11, \n",
      "\n",
      "Turn: 7 | (player_1) Legal pieces : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], Legal moves total: 179, Remaining pieces: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Turn: 7 | Action: 521, Piece: 4, Position: (6, 4), \n",
      "Turn: 7 | Reward: -1, Cumulative reward: 7, \n",
      "\n",
      "SCORE (player_1): 0.33, Squares/turn: 4.33, Remaining pieces difference: -2, Territory difference: -2\n",
      "SCORE (player_0): 9.00, Squares/turn: 5.00, Remaining pieces difference: 2, Territory difference: 2\n",
      "\n",
      "Turn: 8 | (player_0) Legal pieces : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], Legal moves total: 127, Remaining pieces: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11]\n",
      "Turn: 8 | Action: 1103, Piece: 9, Position: (4, 1), \n",
      "Turn: 8 | Reward: 0, Cumulative reward: 14, \n",
      "\n",
      "Turn: 9 | (player_1) Legal pieces : [0, 1, 2, 3, 5, 6], Legal moves total: 66, Remaining pieces: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11]\n",
      "Turn: 9 | Action: 79, Piece: 1, Position: (1, 7), \n",
      "Turn: 9 | Reward: -1, Cumulative reward: 5, \n",
      "\n",
      "SCORE (player_1): -2.50, Squares/turn: 3.50, Remaining pieces difference: -5, Territory difference: -1\n",
      "SCORE (player_0): 10.75, Squares/turn: 4.75, Remaining pieces difference: 5, Territory difference: 1\n",
      "\n",
      "Turn: 10 | (player_0) Legal pieces : [0, 1, 2, 3, 4, 5, 6], Legal moves total: 70, Remaining pieces: [0, 1, 2, 3, 4, 5, 6, 7, 8, 11]\n",
      "Turn: 10 | Action: 498, Piece: 4, Position: (5, 5), \n",
      "Turn: 10 | Reward: 0, Cumulative reward: 14, \n",
      "\n",
      "Turn: 11 | (player_1) Legal pieces : [0, 2, 3, 5, 6], Legal moves total: 32, Remaining pieces: [0, 2, 3, 5, 6, 7, 8, 9, 10, 11]\n",
      "Turn: 11 | Action: 286, Piece: 3, Position: (3, 0), \n",
      "Turn: 11 | Reward: -1, Cumulative reward: 3, \n",
      "\n",
      "SCORE (player_1): -3.80, Squares/turn: 3.20, Remaining pieces difference: -6, Territory difference: -1\n",
      "SCORE (player_0): 11.40, Squares/turn: 4.40, Remaining pieces difference: 6, Territory difference: 1\n",
      "\n",
      "Turn: 12 | (player_0) Legal pieces : [0, 1, 2, 3, 5, 6], Legal moves total: 45, Remaining pieces: [0, 1, 2, 3, 5, 6, 7, 8, 11]\n",
      "Turn: 12 | Action: 262, Piece: 3, Position: (1, 3), \n",
      "Turn: 12 | Reward: -1, Cumulative reward: 13, \n",
      "\n",
      "Turn: 13 | (player_1) Legal pieces : [0, 2, 5], Legal moves total: 15, Remaining pieces: [0, 2, 5, 6, 7, 8, 9, 10, 11]\n",
      "Turn: 13 | Action: 195, Piece: 2, Position: (4, 3), \n",
      "Turn: 13 | Reward: -1, Cumulative reward: 1, \n",
      "\n",
      "SCORE (player_1): -4.00, Squares/turn: 3.00, Remaining pieces difference: -6, Territory difference: -1\n",
      "SCORE (player_0): 11.00, Squares/turn: 4.00, Remaining pieces difference: 6, Territory difference: 1\n",
      "\n",
      "Turn: 14 | (player_0) Legal pieces : [0, 1, 2, 5], Legal moves total: 24, Remaining pieces: [0, 1, 2, 5, 6, 7, 8, 11]\n",
      "Turn: 14 | Action: 85, Piece: 1, Position: (2, 5), \n",
      "Turn: 14 | Reward: -2, Cumulative reward: 10, \n",
      "\n",
      "Turn: 15 | (player_1) Legal pieces : [0, 5], Legal moves total: 9, Remaining pieces: [0, 5, 6, 7, 8, 9, 10, 11]\n",
      "Turn: 15 | Action: 48, Piece: 0, Position: (6, 0), \n",
      "Turn: 15 | Reward: -2, Cumulative reward: -2, \n",
      "\n",
      "SCORE (player_1): -4.29, Squares/turn: 2.71, Remaining pieces difference: -6, Territory difference: -1\n",
      "SCORE (player_0): 10.57, Squares/turn: 3.57, Remaining pieces difference: 6, Territory difference: 1\n",
      "\n",
      "Turn: 16 | (player_0) Legal pieces : [0, 2, 5], Legal moves total: 13, Remaining pieces: [0, 2, 5, 6, 7, 8, 11]\n",
      "Turn: 16 | Action: 1, Piece: 0, Position: (0, 1), \n",
      "Turn: 16 | Reward: -2, Cumulative reward: 6, \n",
      "\n",
      "Turn: 17 | (player_0) Legal pieces : [2], Legal moves total: 2, Remaining pieces: [2, 5, 6, 7, 8, 11]\n",
      "Turn: 17 | Action: 129, Piece: 2, Position: (0, 0), \n",
      "Turn: 17 | Reward: 0, Cumulative reward: 6, \n",
      "Truncated\n",
      "\n",
      "WINNER:  1\n",
      "\n",
      "player_0 Final reward: 0\n",
      "player_0 Cumulative reward: 6\n",
      "player_0 Final remaining pieces: ['Inn2', 'Bridge', 'Square', 'Manor', 'Infirmary']\n",
      "player_0 Score: 13.11, Squares/turn: 3.11, Remaining pieces difference: 9, Territory difference: 1\n",
      "\n",
      "player_1 Final reward: -2\n",
      "player_1 Cumulative reward: -6\n",
      "player_1 Final remaining pieces: ['Inn2', 'Bridge', 'Square', 'Manor', 'Abbey', 'Academy', 'Infirmary']\n",
      "player_1 Score: -7.29, Squares/turn: 2.71, Remaining pieces difference: -9, Territory difference: -1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "\n",
    "iter = 1\n",
    "\n",
    "# Agent_id can be 0 or 1 : indicates starting player\n",
    "if starting_player == \"AI\":\n",
    "    human_agent_id = 1\n",
    "else:\n",
    "    human_agent_id = 0\n",
    "\n",
    "manual_policy = ManualPolicy(env, agent_id=human_agent_id) # Policy controlled by player\n",
    "\n",
    "while env.agents:\n",
    "    observation, reward, termination, truncation, info = env.last()\n",
    "    mask = observation[\"action_mask\"]\n",
    "    legal_moves = [i for i, valid in enumerate(observation[\"action_mask\"]) if valid]\n",
    "    agent = env.agent_selection\n",
    "\n",
    "    print(\n",
    "        f\"\\nTurn: {iter} | ({agent}) \"\n",
    "        f\"Legal pieces : {list(env.legal_pieces[agent])}, \"\n",
    "        f\"Legal moves total: {np.count_nonzero(mask)}, \"\n",
    "        f\"Remaining pieces: {env.board.unplaced_pieces[agent]}\"\n",
    "    )\n",
    "\n",
    "    if agent == manual_policy.agent:                # Human action\n",
    "        action = manual_policy(observation, agent)\n",
    "    else:                                           # AI action\n",
    "        state = observation[\"observation\"]\n",
    "        action = select_action_dqn(policy_net, state, mask, device)\n",
    "\n",
    "    env.step(action)\n",
    "\n",
    "    print(\n",
    "        f\"Turn: {iter} | \"\n",
    "        f\"Action: {action}, \"\n",
    "        f\"Piece: {env.board.action_to_piece_map(action)[0]}, \"\n",
    "        f\"Position: {env.board.action_to_pos_rotation_mapp(agent, action)[0]}, \"\n",
    "    )\n",
    "    print(\n",
    "        f\"Turn: {iter} | Reward: {env.rewards[agent]}, \"\n",
    "        f\"Cumulative reward: {env._cumulative_rewards[agent]}, \"\n",
    "    )\n",
    "    if env.turns[\"player_0\"] == env.turns[\"player_1\"]:\n",
    "        print()\n",
    "        for agent in env.agents:\n",
    "            print(\n",
    "                f\"SCORE ({agent}): {env.score[agent]['total']:0.2f}, \"\n",
    "                f\"Squares/turn: {env.score[agent]['squares_per_turn']:0.2f}, \"\n",
    "                f\"Remaining pieces difference: {env.score[agent]['remaining_pieces']}, \"\n",
    "                f\"Territory difference: {env.score[agent]['territory']}\"\n",
    "            )\n",
    "\n",
    "    iter += 1\n",
    "\n",
    "print(\"Terminated\") if termination else print(\"Truncated\")\n",
    "print(\"\\nWINNER: \", env.winner)\n",
    "for agent in env.possible_agents:\n",
    "    print(f\"\\n{agent} Final reward: {env.rewards[agent]}\")\n",
    "    print(f\"{agent} Cumulative reward: {env._cumulative_rewards[agent]}\")\n",
    "    print(\n",
    "        f\"{agent} Final remaining pieces: {[p.name for p in env.final_pieces[agent]]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{agent} Score: {env.score[agent]['total']:0.2f}, \"\n",
    "        f\"Squares/turn: {env.score[agent]['squares_per_turn']:0.2f}, \"\n",
    "        f\"Remaining pieces difference: {env.score[agent]['remaining_pieces']}, \"\n",
    "        f\"Territory difference: {env.score[agent]['territory']}\"\n",
    "    )\n",
    "pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf573",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
